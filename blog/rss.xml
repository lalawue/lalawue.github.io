<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet href="../styles/rss_style.css" type="text/css"?>
<rss version="2.0"
     xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
     xmlns:dc="http://purl.org/dc/elements/1.1/"
     xmlns:admin="http://webns.net/mvcb/"
     >
  <channel>
    <title>Sucha's Blog</title>
    <link>http://suchang.net/blog/index.html</link>
    <description>linux, emacs, programming, live and essay</description>
    <pubDate>Tue, 09 Dec 2014 20:16:37 +0800</pubDate>
    <generator>emacs-wiki-journal</generator>
    <language>zh-CN</language>
    <dc:creator>suchaaa@gmail.com (sucha)</dc:creator>

    <item>
      <title>OpenGL 3.3 under MacOS</title>
      <guid>http://suchang.net/blog/2014-12.html#p1</guid>
      <pubDate>2014-12-09T19:42:30+0800</pubDate>
      <dc:creator>sucha</dc:creator>
      <category>CategoryProgramming</category>
      <description><![CDATA[<p>
其实我想说的是在黑苹果下的情况，一般阿婆是只打开 OpenGL 2.1 而已的，用
X11 XQuartz 或者 GLEW，都无法使用 OpenGL 3.3 的，对于我这个初学者来说，
想从 Modern OpenGL 入门，痛苦不堪。

</p>

<p>
首先，还是先确认黑苹果在硬件上能够支持的 OpenGL API 版本吧，App Store 上
下载 OpenGL Extensions Viewer 来确认硬件情况，比如我的是 <a class="nonexistent" href="mailto:suchaaa@gmail.com">GeForce</a> 310，是
能够支持到 OpenGL 3.3 Core 的。

</p>

<p>
剩下的就是驱动问题了，谷歌得到的结果是建议用新的 GLFW 而不是 GLUT 或者
GLEW 来做，GLFW 在 MacOS 下默认也只打开 OpenGL 2.1 而已，听说要这样才能
打开 3.3 的 Core：

</p>

<pre class="source"><span class="keyword">static</span> <span class="type">void</span> <span class="function-name">using_opengl_version_330</span>(<span class="type">void</span>) {
    glfwWindowHint(GLFW_CONTEXT_VERSION_MAJOR, 3);
    glfwWindowHint(GLFW_CONTEXT_VERSION_MINOR, 3);
    glfwWindowHint(GLFW_OPENGL_PROFILE, GLFW_OPENGL_CORE_PROFILE);
    glfwWindowHint(GLFW_OPENGL_FORWARD_COMPAT, GL_TRUE);
}
</pre>


设置完之后，我就按教程走了，但是，又出现了意外的情况，在我的黑苹果上面，
#version 330 的 shader 源码都编译链接过了，但就是没有显示，窗口里面都是
黑的。总之 OpenGL 2.1 可以，3.3 就是不行。即便 glClear 颜色显示 OK，loop
循环也有走。

</p>

<p>
又不甘心使用 OpenGL 2.1 呢，只好救助于 Apple 原生的系统接口看看了，还好
谷歌查到了不错的东西 <a href="https://developer.apple.com/library/mac/samplecode/GLEssentials/Introduction/Intro.html">GLEssentials</a>，是官方提供的 Objective-C 使用 OpenGL
3.3 API 编程的例子。

</p>

<p>
立马左上角的 "Download Sample Code"，XCode 打开工程瞬间编译完成，看了一
下接口以及 Shader，确认是使用 OpenGL 3.3 接口无疑，demo 也挺高大上的，果
然官方的东西就是妥妥的。

</p>

<p>
之前依靠跨平台各种库、以及过时的库起步，加上黑苹果的原因吧，缓慢起步。

</p>

]]></description>
    </item>

    <item>
      <title>实践了一个 JPEG 解码器</title>
      <guid>http://suchang.net/blog/2014-12.html#p0</guid>
      <pubDate>2014-12-01T22:53:41+0800</pubDate>
      <dc:creator>sucha</dc:creator>
      <category>CategoryProgramming</category>
      <description><![CDATA[<p>
为了更好地了解 JPEG 的解码过程，实践了一个 JPEG 解码器，放到个人 github
上面了，<a href="http://github.com/lalawue/jpeg_dec">http://github.com/lalawue/jpeg_dec</a>.

</p>

<p>
参考了不少中英文资料，更多的是中文的，marker 的部分倒是看了 itu-81 的图表。

</p>

<p>
不需要用 shadowsocks 翻墙技能，仅靠百度到的中文博客歪歪斜斜排版杂乱不堪
的文章，其实也能从无到有实践一个 JPEG 解码器。

</p>

<p>
也参考了不少 nanojpeg 的代码以及处理流程，最复杂的部分，在我看来是霍夫曼
编码的生成，是自己理解得不好，数据结构课上面的霍夫曼编码部分忘得差不多了。

</p>

<p>
而 nanojpeg 包括 public domain 的 c++ jpegd 实现的霍夫曼码，其生成我感觉
都不明晰，所以花了不少时间。这个部分倒是中文的某些博客写得很清楚，虽然这
些博客其实也是不知道从哪里抄的（未必是博主第一手资料，且有些还无来源）。

</p>

<p>
实现了霍夫曼表后，接下来的困难是 IDCT 的部分，看了几个解码库的，包括
libjpeg 的，README 里面写得明明白白：

</p>

<pre>
If you think that you know about DCT-based JPEG after reading this book,
then you are in delusion.
</pre>

<p>
所以就不琢磨了，说不好都是优化过的代码，调试出来的，不是给人看的，这部分
直接来自 nanojpeg，是一个整型使用位移调整精度的 IDCT 算法，传说的 AA&N
算法，如 libjpeg 里面的，没有看得很明白，其实 jpgd c++ 用的跟 libjpeg 一
样，有用到浮点就是。

</p>

<p>
然后是一些细节问题，估计看 ITU-81 里面也难看得明白，比如霍夫曼的 VLC 部
分其实我是根据 nanojpeg 的输出比对排错的、IDCT 的部分也是；还有读到
0xffd9 后补齐 bits 的问题，都补 binary 1；以及每个 component 的 dc
restart interval 问题等等。

</p>

<p>
八卦一下，Mac 下面预览导出的 jpeg 图片，霍夫曼表是一个 DHT segment 带一
个的，PS 则是一个 DHT segment 带多个的。

</p>

<p>
前人也总结了太多有关 JPEG 结构、解码所需要的知识，这里不重复了，评论下看
到的一些源码吧。

</p>

<p>
首先目前自己实现的是一个仅支持 Baseline DCT、H1V1 chroma sampling、<a class="nonexistent" href="mailto:suchaaa@gmail.com">YCbCr</a>
色彩的 JPEG decoder。其实绝大部分的 JPEG 都是 Baseline、H1V1 的，Gray
Scale 其实要比 <a class="nonexistent" href="mailto:suchaaa@gmail.com">YCbCr</a> 的简单，再看看后续要不要加上。

</p>

<p>
nanojpeg 为了实现的简单，资源都全部先申请，包括输出的图片缓冲，亮点是为
了霍夫曼解码的方便，每个霍夫曼表开了个 1^16 条目的数组，将最多 256 个实
际变长码 map 到里面去，这种 LUT 的时间效率没得说了，它自己也介绍说解码时
间上面只比 libjpeg 慢一点点（不支持多线程）。不过空间使用率到了这个地步，
为啥不像下面的解码库一样，对 YUV 转 RGB 也先做 LUT 呢。

</p>

<p>
而 jpgd c++ 是个 public domain 的解码库，看了一下作者，之前在 Valve 呢，
现在项目合并到了 JPEG encoder 里面去，最后的更新是 2012 年的。其霍夫曼变
长码是将常用的长度小于 8 bits 的 VLC map 到一个 1^8 的空间里面去，剩下的
放到一个 512 大小的空间里面进行二次查询，两个 LUT 加上一个顺序查找的空间
（应该是顺序查找的吧，命名为 tree 的）。

</p>

<p>
小于 7 bits 的变长码，一次 lookup 就可以定位，超过 7 bits，则需要一个个
bits 来顺序检测并跳转查找了。

</p>

<p>
jpgd c++ 的最大亮点，在于将 YUV 转 RGB 的部分，做了 LUT。这个空间消耗很
小，比 nanojpeg 丧心病狂的 1^16 LUT 空间少了 N 个数量级，且效率很显著，
特别是当图片变大，像素越来越多的时候。

</p>

<p>
后续有时间，我也想弄一个稍微改进点的霍夫曼变长码检测方法、以及 YUV 转RGB
的 LUT，目前霍夫曼编码部分是完全按照位数长度从小到大顺序检测的，非常非常
耗时，只是作为一个样例来理解的话，倒还好。

</p>

]]></description>
    </item>

  </channel>
</rss>
